# Struggle

Learning to code has always been a process rooted in _struggle_. Not frustration for its own sake, but a particular kind of intellectual friction — the _productive struggle_ that arises when a learner is forced to wrestle with an error, trace a logic bug, or refactor messy code into a clean solution. It is in these moments of difficulty that deep learning occurs: learners begin to internalize abstract concepts, develop debugging intuition, and gain confidence in their ability to reason through uncertainty. Productive struggle has long been seen as a rite of passage in computer science (CS) — and not without reason.

To many students, especially beginners, this struggle can feel like punishment and thus an obstacle between them and “getting it.” In that sense, some steps of learning to code can resemble the famous “wax on, wax off” scene from _The Karate Kid_: a repetitive, seemingly pointless effort that only later reveals its purpose. Within physical activities this is painfully clear to everyone: no one expects  to learn landing a skateboard trick, shooting a perfect basketball throw, or playing a piano sonata without dozens of failed attempts. More likely, hundreds. The effort is frustrating, of course, but it is also expected, even embraced. Writing (and rewriting) lots of code, getting unstuck from blocks or bugs, and slowly building a mental model of how the machine works — this is the "muscle memory" of computing. In CS, we have not always done a good job of explaining that the struggle is not a sign of failure, but the very substance of learning.

However, this productive struggle is valuable only when learners feel supported. Without guidance or community, struggle quickly becomes frustration, and frustration often leads to attrition or even withdrawal. This is probably the case for a feeling of exclusion of countless potential programmers.

Generative AI tools such as ChatGPT, GitHub Copilot, and similar technologies are now entering education and changing the premise fast. It's a new powerful assistance that can write or explain code, fix bugs, or answer direct questions. It also introduces a significant challenge. If learners rely excessively on AI, they risk bypassing essential stages of learning. What initially feels like helpful support can quickly become a crutch, potentially depriving learners of the critical growth that comes from wrestling with difficult problems.

This challenge is not new. For decades, tools designed to simplify programming have posed similar risks. Integrated Development Environments (IDEs) provide code completion and instant error detection. Stack Overflow allows learners to copy and paste solutions without fully understanding them. Online tutorials and videos guide learners step-by-step through problems, often without requiring them to actively engage with the logic involved. Pre-written templates and boilerplates from repositories like GitHub mean that students frequently begin with ready-made code rather than starting from scratch. Which is fine.

Each innovation made programming more accessible but introduced new risks of superficial learning. Educators responded by adjusting their teaching methods, emphasizing reasoning, reflection, and process-oriented evaluation. Generative AI doesn’t just assist with programming — it can do much of it. And it demands a similar, perhaps even deeper, pedagogical shift.

The encouraging news is that AI provides an opportunity—not just a threat. It allows educators to reimagine teaching in ways that significantly enhance learning for everyone, not just the most persistent students. AI can scaffold learning experiences, making productive struggle more meaningful and less isolating. It provides immediate examples, detailed explanations, and instant feedback tailored to each learner’s needs, allowing students to shift their focus from simply making code work to deeply understanding why and how it works.

For this positive outcome to occur, we must position AI as a collaborative partner, not a replacement for critical thinking. This approach requires transferring greater ownership and responsibility to learners. Students should be encouraged—and expected—to explain their code, debug it when it fails, improve it iteratively, and adapt solutions creatively to new contexts. If AI generates a first draft, learners must still be able to refine, critique, and take ownership of the final version.

### subtitle 1

Fortunately, effective educational strategies already exist to promote collaborative meaningful learning in computer science. Peer instruction, studio-based learning, and pair programming are especially well-suited to integrate AI thoughtfully and effectively.

Peer instruction fundamentally reshapes the traditional lecture-based classroom by placing active student engagement at its center. Students prepare by engaging with assigned materials, often enhanced by personalized AI support. During class, they encounter conceptual questions designed to uncover misconceptions. Students first individually reflect and vote on their answers, then discuss their reasoning in groups, and finally vote again. This interactive process transforms lectures into dynamic, student-driven dialogues. Even outside the structured lecture environment, peer learning transforms collaborative activities, with students critically evaluating and refining AI-generated content together, reinforcing collective understanding and critical thinking skills.

Studio-based learning, drawn from architecture, art, and design education, emphasizes iterative creation, regular critiques ("crits"), and ongoing public exposure of work. Historically, students in these fields shared physical studios or workshops, making their processes continuously visible to peers. Informal observation, feedback, and structured critique sessions reinforced iterative improvement. Integrating AI into studio contexts further enriches this tradition. Students not only present their evolving solutions but also transparently document their AI interactions, reflecting on each step of their decision-making. This visibility enhances accountability and encourages deeper engagement with both the AI tools and the learning process itself.

Pair programming, widely adopted in the software industry, involves two programmers working collaboratively at a single workstation. One writes the code (the "driver"), while the other actively reviews and guides the process (the "navigator"). This method enhances software quality, reduces errors, and promotes continuous professional learning. Introducing AI into pair programming sessions deepens this collaborative dynamic. Pairs critically analyze AI-generated suggestions, fostering dialogue about the logic, efficiency, and readability of proposed solutions. Such collaborative reflection reinforces critical thinking and mirrors real-world software development practices, preparing students effectively for industry demands.

### subtitle2 

Ultimately, AI’s greatest potential in education lies not merely in automating tasks but in transforming how we approach teaching and learning. Historically, computer science has often appeared intimidating, exclusive, or only suited to a particular type of learner. Generative AI can fundamentally change this perception, making the field more approachable, supportive, and inclusive.

AI can lower barriers to entry, provide continuous support outside traditional classroom hours, make experimentation less intimidating, and empower learners to pursue projects they genuinely care about. However, achieving these outcomes requires prioritizing human-centric values: reflection, ownership, and learner agency. Students must learn not only to write code but also to think critically about it, clearly explain it, and deeply care about its implications.

Rather than shielding students from AI, educators must equip them to use these tools wisely, creatively, and critically. Doing so can make learning to code—and learning itself—more accessible, meaningful, and deeply human than ever before.

